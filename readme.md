ğŸš¦ IoT-Based Smart Traffic Analytics Pipeline

End-to-End Data Engineering Project simulating IoT traffic sensors, building batch + streaming pipelines, and visualizing real-time insights on a dashboard â€” with direct database integration.

ğŸ“Œ Project Overview

Modern smart cities rely on IoT traffic sensors to monitor vehicles, detect congestion, and improve road safety.
This project simulates such a system by:

Generating realistic traffic data (vehicle ID, speed, location, timestamp).

Ingesting data directly into a database instead of flat files.

Processing it in batch ETL pipelines for historical insights.

Streaming it in real-time pipelines for live alerts.

Visualizing insights on a dashboard for monitoring.

This project demonstrates core data engineering skills:
âœ… IoT Data Simulation
âœ… Database Ingestion (SQLite â†’ Azure SQL / Data Lake)
âœ… Batch ETL with Pandas & SQL
âœ… Streaming Analytics with Kafka / Azure Stream Analytics
âœ… Real-Time Dashboards

ğŸ¯ Objectives

Simulate IoT Traffic Data â€“ Python script generates live traffic events into a database.

Batch Data Pipeline (ETL) â€“ Clean, transform & load processed data into a new table.

Streaming Analytics â€“ Real-time alerts for overspeeding, congestion, and accidents.

Dashboard & Reporting â€“ Visualize metrics and summarize findings.

ğŸ› ï¸ Tech Stack
Layer	Tools & Technologies
Data Simulation	Python (random, faker)
Database	SQLite (local), Azure SQL Database
Batch Processing	Pandas, SQL queries
Streaming	Azure Stream Analytics / Apache Kafka
Storage	SQL Database, Azure Data Lake
Visualization	Power BI / Streamlit / Grafana
Big Data (Optional)	Spark, Hadoop
Orchestration (Optional)	Airflow
ğŸ“‚ Project Structure
ğŸ“¦ smart-traffic-analytics
 â”£ ğŸ“œ README.md
 â”£ ğŸ“œ traffic_simulator.py      # Data generator â†’ Database ingestion
 â”£ ğŸ“œ traffic.db                # SQLite database (raw traffic data)
 â”£ ğŸ“œ traffic_etl.py            # Batch ETL pipeline
 â”£ ğŸ“œ processed_traffic.db      # Processed table (after ETL)
 â”£ ğŸ“œ streaming_pipeline/       # Real-time processing setup
 â”£ ğŸ“œ dashboard/                # Dashboard code (Power BI / Streamlit)
 â”£ ğŸ“œ report/                   # Final PDF Report

ğŸš€ Milestones
Milestone 1: Data Simulation (Database-First)

âœ… Python script simulates traffic data:

vehicle_id, speed, location, timestamp.

âœ… Data ingested directly into traffic.db (SQLite).

Sample Record:

V605 | 133 | Downtown    | 2025-09-03 06:12:38
V744 | 56  | Highway A1  | 2025-09-03 06:12:43

Milestone 2: Batch ETL Pipeline

âœ… Extract: Read raw traffic data from traffic.db.

âœ… Transform:

Flag overspeeding vehicles (>120 km/h).

Compute average speeds per location.

Handle duplicates/missing values.

âœ… Load: Save processed data into new table (processed_traffic).

Milestone 3: Streaming Analytics

âœ… Send real-time events to Azure Event Hub / Kafka.

âœ… Process streams with Azure Stream Analytics.

âœ… Generate alerts for:

Overspeeding.

Sudden congestion (avg speed drop).

Accidents (vehicles stuck at 0 km/h).

Milestone 4: Dashboard & Reporting

âœ… Dashboard (Power BI / Streamlit / Grafana).

âœ… Real-time monitoring:

Vehicle speeds per road.

Live alerts.

Rush-hour congestion trends.

âœ… Final PDF Report with:

System architecture.

Key insights.

Performance results.

ğŸ“Š System Architecture
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Data Source â”‚  (Python IoT Generator â†’ Database)
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   Batch ETL   â”‚ (Pandas + SQL)
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Processed DB  â”‚ (SQLite â†’ Azure SQL / Data Lake)
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  Streaming    â”‚ (Kafka / Azure Stream Analytics)
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  Dashboard    â”‚ (Power BI / Streamlit)
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“¸ Screenshots (to add later)

âœ… Console logs of data insertion into DB.

âœ… Raw traffic_data table in SQLite.

âœ… Processed ETL table with flagged anomalies.

âœ… Dashboard with real-time metrics.

ğŸ† Final Deliverables

Python scripts (traffic_simulator.py, traffic_etl.py).

Databases (traffic.db, processed_traffic.db).

Streaming pipeline config (Azure/Kafka).

Dashboard (Power BI / Streamlit).

Final Report (PDF) documenting:

Pipeline architecture.

Key insights.

System performance.

ğŸ‘¥ Team Roles
Role	Member Responsibility
Data Simulation Lead	Python generator â†’ Database ingestion
Batch ETL Engineer	Build ETL logic with Pandas + SQL
Streaming Engineer	Kafka / Azure Stream Analytics
Cloud Architect	Azure SQL, Event Hub, Data Lake setup
Dashboard Developer	Power BI / Streamlit dashboards
Project Manager	Integration + final report
ğŸŒŸ Key Learnings

IoT data ingestion directly into databases.

Batch analytics with Pandas & SQL.

Streaming pipelines for real-time traffic monitoring.

Building dashboards for live insights.

Deploying pipelines to cloud platforms.

ğŸ“œ License

This project is for educational purposes as part of a Data Engineering course.